{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run 'processing'\n",
    "%run 'normalisasi'\n",
    "%run 'case_folding'\n",
    "%run 'stop_word'\n",
    "%run 'stemmer'\n",
    "%run 'bag_of_word'\n",
    "%run 'word2vec'\n",
    "%run 'transform_fitur'\n",
    "from MyXML import MyXML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load semua file and gabungin\n",
    "data_opini_1 = MyXML('./data/anotated/2016.xml')\n",
    "data_opini_2 = MyXML('./data/anotated/2017.xml')\n",
    "data_opini_3 = MyXML('./data/anotated/2018.xml')\n",
    "data_opini_4 = MyXML('./data/anotated/2019.xml')\n",
    "data_opini = data_opini_1.get_pair().copy()\n",
    "data_opini += data_opini_2.get_pair()\n",
    "data_opini += data_opini_3.get_pair()\n",
    "data_opini += data_opini_4.get_pair()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split kalimat\n",
    "data_opini = split_multi_aspek(data_opini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalisasi\n",
    "data_opini = normalisasi(data_opini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalisasi pakai inaNLP\n",
    "data_opini = ina_nlp_formalizer(data_opini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lebih baik mahasiswa ditekankan untuk memakai  adab sebelum ilmu  atau etika dalam menuntut ilmu supaya kelas kondusif dan mendapatkan berkah  \n"
     ]
    }
   ],
   "source": [
    "# case folding\n",
    "data_opini = case_folding_and_remove_number(data_opini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_opini_v2(baru).txt saved\n"
     ]
    }
   ],
   "source": [
    "# save data opini\n",
    "save_data_opini(data_opini, 'data_opini_v2(baru).txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data opini\n",
    "data_opini = open_data_opini('data_opini_v2(baru).txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf-idf\n",
    "dict_tf_idf = tf_idf_dict(data_opini)\n",
    "fitur_tf_idf = transform_bag_of_words(dict_tf_idf, data_opini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorizer = TfidfVectorizer()\n",
    "#list_kalimat = []\n",
    "#for text, opini in data_opini:\n",
    "#    list_kalimat.append(text)\n",
    "#x = vectorizer.fit_transform(list_kalimat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(x.shape)\n",
    "#print(vectorizer.get_feature_names())\n",
    "#print(len(vectorizer.get_feature_names()))\n",
    "#dict_tf_idf\n",
    "#vectorizer.vocabulary_\n",
    "#min(vectorizer.idf_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitur postagger\n",
    "fitur_pos_tag = transform_pos_tagger(data_opini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitur word2vec\n",
    "fitur_word2vec = transform_word2vec_average(data_opini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling tfidf\n",
    "from sklearn import preprocessing\n",
    "fitur_tf_idf = np.array(fitur_tf_idf)\n",
    "fitur_tf_idf = preprocessing.scale(fitur_tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling postagger\n",
    "fitur_pos_tag = np.array(fitur_pos_tag)\n",
    "fitur_pos_tag = preprocessing.scale(fitur_pos_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.31485638e-15, -1.33473137e-15, -3.57088376e-16, -1.87382857e-15])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitur_pos_tag.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling word2vec\n",
    "fitur_word2vec = np.array(fitur_word2vec)\n",
    "fitur_word2vec = preprocessing.scale(fitur_word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gabung semua fitur\n",
    "import numpy as np\n",
    "X = []\n",
    "for i in range(0, len(fitur_tf_idf)):\n",
    "    X.append(np.concatenate((fitur_tf_idf[i], fitur_pos_tag[i], fitur_word2vec[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform label\n",
    "Y = transform_label(data_opini)\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(Y)\n",
    "YY = le.transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train , X_test , y_train, y_test = train_test_split(X, YY, random_state=109, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(decision_function_shape='ovo')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training\n",
    "from sklearn import svm\n",
    "clf = svm.SVC(decision_function_shape='ovo', kernel='rbf')\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.674364896073903\n",
      "Precision: 0.674364896073903\n",
      "Recall: 0.674364896073903\n"
     ]
    }
   ],
   "source": [
    "#show acuraccy\n",
    "from sklearn import metrics\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred, average='micro'))\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# play with model\n",
    "kalimat = \"ruangan sangat panas\"\n",
    "data = [[kalimat, [['NoAspect', 'Positif']]]]\n",
    "kalimat_tfidf = transform_bag_of_words(dict_tf_idf, data)\n",
    "for i in range(0, 96 - len(kalimat_tfidf[0])):\n",
    "    kalimat_tfidf[0].append(0.0)\n",
    "kalimat_pos_tag = transform_pos_tagger(data)\n",
    "kalimat_word2vec = transform_word2vec_average(data)\n",
    "\n",
    "kalimat_tfidf = np.array(kalimat_tfidf)\n",
    "kalimat_tfidf = preprocessing.scale(kalimat_tfidf)\n",
    "\n",
    "kalimat_pos_tag = np.array(kalimat_pos_tag)\n",
    "kalimat_pos_tag = preprocessing.scale(kalimat_pos_tag)\n",
    "\n",
    "kalimat_word2vec = np.array(kalimat_word2vec)\n",
    "kalimat_word2vec = preprocessing.scale(kalimat_word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "A = []\n",
    "for i in range(0, len(kalimat_tfidf)):\n",
    "    A.append(np.concatenate((kalimat_tfidf[i], kalimat_pos_tag[i], kalimat_word2vec[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
